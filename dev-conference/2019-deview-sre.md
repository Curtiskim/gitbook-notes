---
description: site reliability engineering
---

# 2019 deview SRE 참관 후기

안녕하세요 평범한 개발자 김봉준입니다.

{% hint style="info" %}
아래 내용은 작년 \(2019년\) deview 발표 컨퍼런스 청강이후 작성한 내용입니다.
{% endhint %}

## SRE \( Site Reliability Engineering \) <a id="SRE(SiteReliabilityEngineering)-SRE(SiteReliabilityEngineering)"></a>

네이버 발표자 : 김재헌, 유호균

### 들어가기 앞서... <a id="SRE(SiteReliabilityEngineering)-&#xB4E4;&#xC5B4;&#xAC00;&#xAE30;&#xC55E;&#xC11C;..."></a>

우선적으로 두서없이 적어 죄송합니다

필자는 데브옵스를 잘 모르며, SRE도 잘 모릅니다.. 다만 어디서 주서 들은 내용 및 데뷰에서 들은 내용을 적어봅니다.  
내용이 틀리거나 이상한것이 있다면 댓글로 남겨주세요.

제 생각에는 요즘 데브옵스 데브옵스 라고 하는데 SRE는 약간 데브옵스 개념하고는 다릅니다.

대략적으로 SRE는 시스템의 신뢰성 , 방법론 , 팀문화 에 포커스가 맞춰져 있다고 보면되고  
데브옵스는 운영팀과 개발팀을 하나로 묶어놓고 개발 사이클을 빠르게 \( 배포 ,장애처리 자동화 등등등등등등\) 하고자 하는 구조 이자 문화입니다.

어찌되었건 둘다 강조하는건 팀의 **문화** 라고 볼수있다!!  
두 이야기를 검색해보면 문화가 얼마나 중요한지에 대해서 많이 이야기 하고 있습니다.

우리는 다른팀들과 적이 아니며 하나의 서비스를 함께 구축해 나아가는 동료라고 생각해야 합니다.

블로그 장인이신 조대협님의 블로그에도 이런말이 나옵니다. [참고블로그](https://bcho.tistory.com/1325)

```text
일반적으로 개발팀은 개발속도에 무게를 두고,  운영팀은 시스템 안정성에 무게를 둔다!! 
위 두 개념에 대해서 서로 상충하는 것때문에 서로 싸우게되고 팀간에 분열이 생기며 서로 멀어지게 된다고 .... ( ~~서로 욕하는상황까지..~~)
```

위상황을 방지하고자 해법으로 제시한 내용이 아래 적어둔 구글에서 지필한 책 SRE 의 내용이라고 볼 수 있습니다. \( `class SRE implements Devops` \)  
우선 구글에 sre를 대략적으로 검색해보면 아래와 같이 다섯가지로 대표적으로 설명합니다.

1. 모니터링 지표
2. 용량계획
3. 변경관리
4. 장애처리
5. 문화

그럼 이제 위 다섯가지를 잘 생각해보고 데뷰에서 발표한 내용 후기를 적어보도록 하겠습니다.

### 왜 &gt; SRE 가필요할까 ? <a id="SRE(SiteReliabilityEngineering)-&#xC65C;&gt;SRE&#xAC00;&#xD544;&#xC694;&#xD560;&#xAE4C;?"></a>

우선 한번쯤 봤을법한 책 구글에서 공개하는 서비스개발 운영 노하우 책 중에 SRE 책이 있습니다. [\[참고도서\]](https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=129407308&ttbkey=ttboutsideris1727002&COPYPaper=1)

그래서 네이버 SRE팀 에서 포커스를 맞춘 내용은 위 5가지 내용이랑 동일한데 deview 발표에서는 시간이 짧은 관계로 크게 모니터링과 , 장애 처리 , 문화에 대해서 이야기 해주셨던 것 같습니다.

```text
신뢰성: 네이버 검색 서비스가 정상적으로 제공되는 것
방법론: Availability, Capacity Planning, Monitoring, Contingency Plan
문화 : Post-Mortem, Blameless, Fact-Based 
```

여기서 문화에서도 fact-based 를 강조 했던 것 같습니다.  
또한 이야기 했던것중에서도,, 서비스 규모는 커질수 있지만 엔지니어는 늘어나지 않는다!! 라고 강조해 줬습니다.  
그래서 이제 시스템을 경보 자동화 도 해야하며, 모니터링해야하고 배포에도 자유로워야하고 해당 시스템을 잘 만들어야 한다고합니다.

해당 트랙은 검색팀의 예시를 발표해주셨는데요 .

검색팀에 자연재해와 같은

지진과 같은 재난상황 에서는 기존의 대응방안으로 동작하지 않는다고 했습니다. \( 저희 커머스 시스템 은 이벤트라고 생각하시고 아래 내용을 읽어주면 될 것 같아요 \)

이 재난 상황은 트래픽이 몰리게 되어 있습니다.  
이때 1개의 모듈의 고장으로 전체시스템의 장애가 10분간이나 지속 되었다는건데요. \( 여기서는 네이버 통합검색 시스템\)  
이렇게 되면 하나의 작은 모듈 고장으로 인하여 전체 큰 시스템이 망가지는 현상이 발생 된다고함..그래서 문제를 직시하고 SRE에 대하여 고민을 하고있었으며, 대략적인 장애에 대한 시간을 계산을 해보자 라고 해서 시간계산을 해보니 재난상황이 이러났을때 아래 와 같은 시간으로 흘러간다고 합니다.

```text
장애 탐지  - 2분
증상 완화 -  20분
원인 파악 - 40분
장애 영향도 파악 - 1시간
장애 복구 완료 - 수시간
포스트모텀 작성 - 48 시간
```

이렇게 되면  
**기존 데브옵스 방법론으로는 규모도 재난도 감당할수 없는게 현실이다.**  
라고 생각하여 네이버에서 2016년 SRE의 필요성을 느끼고 2016년 말에 도입을 결정했다고합니다.

### 네이버 검색팀 그들의 SRE에 대한 설명 <a id="SRE(SiteReliabilityEngineering)-&#xB124;&#xC774;&#xBC84;&#xAC80;&#xC0C9;&#xD300;&#xADF8;&#xB4E4;&#xC758;SRE&#xC5D0;&#xB300;&#xD55C;&#xC124;&#xBA85;"></a>

#### tool <a id="SRE(SiteReliabilityEngineering)-tool"></a>

SRE 관련되어 툴이 여러개 나옵니다 .  
kubernetes , zipkin prometheus , stack ,pagerduty , tensorflow , grafana 등..  
하지만 해당팀에서 강조하는건 .. 툴은 중요하지 않다!! `현실에 닥친 문제를 해결하자!!`

또한 기존 시스템 혹은 서비스에 도구를 적용하는데에 고난이 많다고 합니다.  
그래서 도구보다 현실에 자각해야하고, 그래서 우리는 어떻게 극복할까에 초점을 맞춰야 한다고 합니다.

그들이 판단한 문제점은 아래 와 같습니다. \( 우리의 상황과 비슷하다고 볼 수 있습니다. \)

```text
문제점
1. 비상상황 대응 체계의 부재
2. 장애 발생 Detection의 어려움
3. Post-Mortem 문화 부재
4. 전체 시스템 현황 확인 불가
```

#### 1. 비상 상황 대응체계를 만들어보자!! <a id="SRE(SiteReliabilityEngineering)-1.&#xBE44;&#xC0C1;&#xC0C1;&#xD669;&#xB300;&#xC751;&#xCCB4;&#xACC4;&#xB97C;&#xB9CC;&#xB4E4;&#xC5B4;&#xBCF4;&#xC790;!!"></a>

1. contingency plan 을 만들어봦!! 기준을 만들어야함 \( 장애기준 \)  
2. 쉬운 기준으로 한다!! 각 서비스만의 기준을 만들어야함.  
3. 가용량 지표를 만들자 \( 이건 물 용량 그림으로 설명 \)

#### 2. post mortem 문화를 만들어야함. <a id="SRE(SiteReliabilityEngineering)-2.postmortem&#xBB38;&#xD654;&#xB97C;&#xB9CC;&#xB4E4;&#xC5B4;&#xC57C;&#xD568;."></a>

1. 공간을 만들자.!! 장애에 대한 문제를 git 이슈에남긴다!! 자율적으로 남긴다!! \(기록\)  
2. 이때 작성 포맷을 선정해서 해당 작성 포맷을 공유해야함.  
1. 처음 2-3개월은 SRE 작성 사후 분석 습관화하는 문화만 전파한다고해도 성공했다고 한다.  
2. 나중에 자율적 참여 된다고 합니다.  
3. git issues 에 다음과 같이 남깁니다. \( 유관 관련자들 자유롭게 참여 \)

```text
    20191014 service 메일 발송 누락
    20191012 오픈캐스트 서비스 코어 발생
    20191010 책검색 신규문서 지연 업데이트 이슈
    20191007 네이버 쇼핑 증감 데이터 미 반영
```

#### 3. 전체 시스템 현황 파악. \( 모니터링에 대한 내용. , 모니터링은 기존에도 하고있었으며 metric도 잘 쌓고 있었다고함 \) <a id="SRE(SiteReliabilityEngineering)-3.&#xC804;&#xCCB4;&#xC2DC;&#xC2A4;&#xD15C;&#xD604;&#xD669;&#xD30C;&#xC545;.(&#xBAA8;&#xB2C8;&#xD130;&#xB9C1;&#xC5D0;&#xB300;&#xD55C;&#xB0B4;&#xC6A9;.,&#xBAA8;&#xB2C8;&#xD130;&#xB9C1;&#xC740;&#xAE30;&#xC874;&#xC5D0;&#xB3C4;&#xD558;&#xACE0;&#xC788;&#xC5C8;&#xC73C;&#xBA70;metric&#xB3C4;&#xC798;&#xC313;&#xACE0;&#xC788;&#xC5C8;&#xB2E4;&#xACE0;&#xD568;)"></a>

* 하지만 우리는 외주 업체 혹은 타 팀에서 에서 잘해주고 있을까??? 고민이 필요한 상황.. \( APM 도구 활용도는?? log 남기고 있는 것에 대한 활용도는 ?? 누가 하고있지?? 궁금한점이 생기기도 했습니다. \)

아래 내용부터는 조금 기술적인 부분이 설명됩니다. \( 그래도 대략적으로 읽어보시면 감이 옵니다. \)

1. 문제의식 하나의 서비스가 아니라 전체 다양한 시스템을 사용해서 전체 시스템의 현황을 파악해야함  
2. mertric + meta data = insight  
3. 지표를 잘 쌓아야함.. \( 정보가 넘처나는 상황\) ---&gt;&gt; ECP도 정보가 분명 있을텐데.... 잘 모르겠습니다.  
4. 서비스 단위 정보 자동 저장.

* SSUID 발급 -&gt; 서비스 유니크 아이디 발급 \( meta data 발급 api 개발, 그래서 호스트단위가 아니라 서비스단위로 관리\) 이유 : 서버 단위의 알람 기능이 아니라 , 서비스 단위의 알람 기능을 이용하기 위해
* DRI \( 서비스 담당자 \) -&gt; 서비스 담당자에게 직접 보내야함. -&gt; 그런데 담당자 정보는 언제나 다르다 \( 자꾸 핑퐁됨 저 아닌데요?? 외주업체에게 넘기세요 ?? 저 아닌데요 타 부서에게 등등 보내세요... 무한루프\) -&gt; 담당자 정보를 정확하게 기제하게 만들어야한다 \( 해당 서비스에 여기서 meta data api 만들어야한다고 한다 메타관리 시스템 \) -&gt; 그래서 여기서 알람을 받는 대상자도 메타관리 시스템에서 나온 모니터링 담당자가 아니라!!!!! , 서비스 담당자 전체에게 다 보내야함. -&gt; 저 정보를 통해서 담당자 정보를 통해서 해당 담당자가 없을경우 부사수 , 팀장 팀 등등 다 적어야함 \( 메타관리 시스템 \)
* ab 테스트 등 ,성능테스트 하고 싶을테 , 실제 프로덕션 시스템에 한대 늘려서 할때!! -&gt; environment 장비 환경정보를 저장할수있게 메타데이터 관리를 해줘야함. -&gt; 그래서 이게 지표에 대한걸 합산할때 서비스 합산 지표에서 해당 ab 테스트 장비에대한걸 뺄수있도록 개발되어야한다고함.

**그래서 결론적으로 어떤식으로 위 시스템이 운영되어야 하냐면 , `이상 탐지 - 가시화 - 경보발송` 이런식으로 자동화 되어야 한다고 합니다.**

* aggregation
  1. 그래서 통합 모니터링 시스템을 개발했다. \( 시스템 소개는 생략 \)
  2. SRE 팀의 목표가 이 시스템을 만드는 것 이였지만 이제는 시스템만드는게 목표가 아니라 실패를 통한 개선을 하는 목표로 바꿈

좀더 자세한 내용은 deview 2019 SRE 트랙 참고자료를 보시면 됩니다. \( [참고자료](https://deview.kr/data/deview/2019/presentation/%5B223%5DFail%20Fast,%20Learn%20Faster%20SRE%20%28%EC%8B%A4%ED%8C%A8%EC%97%90%EC%84%9C%20%EB%B0%B0%EC%9B%8C%EB%82%98%EA%B0%80%EB%8A%94%20SRE%29_comp.pdf) \)

### Fail Fast, Learn Faster <a id="SRE(SiteReliabilityEngineering)-FailFast,LearnFaster"></a>

네이버 SRE 팀에서 해당 트랙에서 말하는 내용은 **장애와 어떻게 효과적으로 싸울까**를 고민하는 것 같습니다.  
또한 실패를 통한 개선 SRE의 궁극적인 목표인 것 같음.

```text
이게 장애대 대해서 서로 팀간의  너무 민감하게 반응하지 않고 , ( 서로를 비난하지 않는 문화 ) 장애 발생후에 이를 회고 하고 향후에 대책을 수립하는 postmortem 회고를 수행해야한다고 합니다.
```

**시간을 줄여보자**

그래서 어찌되었건 장애가 발생되면 위에 내용중에 재난상황이 났을경우 이상징후부터 해결까지 시간을 나타낸것이 있는데.  
여기서 줄일수 있는 시간을 SRE팀은 생각해 봅니다.

복구와 상세 원인 및 분석 재발 방지 는 시간을 줄일수 없다고 판단하고 ,

**이상징후 탐지와 , 의사결정 , 영향도 파악 시간은 실질적으로 줄일 수 있다고 판단합니다.**

**모니터링 시스템은 ?**

그래서 모니터링 경보 시스템을 구축하고 해당 경보 시스템을 너무 민감하게하면 경보 피로도가 쌓이고.. 이럴좀 더 느슨하게 풀게되고 이와 같은 과정을 반복하면서  
해당 서비스에 맞는 모니터링 경보 시스템을 만들어 가는 내용을 설명해줍니다.

여기에서는 경보를 튜닝하여 거짓경보에 대한내용을 줄여야 하고 \( ex\) cpu 임계치 , mem 임계치 등등 \)

**장애 경보는 ?**

우선적으로 다양한 경보를 수신하고, 고통스러울때 튜닝을 해야한다고 합니다.  
또한 텐서플로우나 다양한 툴을 이용해서 패턴을 분석하고 자동감지 패턴을 도입 했다고 합니다.

**그래서 ?**

그래서 궁극적으로 이렇게 되면 , 해당 팀에서는 장애영양도 파악이 1시간에서 5분으로 줄었다고 함.

**결론 ?**

여기서 이 팀의 키워드는!!!!!! 다음과 같습니다.

**빠르게 실패하고 , 빠르게 배워서 \[개선\] 한다.**

여기서 재미있는 일화를 이야기해주는데요. **서비스가 업데이트되면 필연적으로 장애**가 발생하게 되는데 \( 개발자라면 알수있는 고통.... ㅠ\_ㅠ \)  
이 업데이트 대비 장애 비율이 점차적으로 감소한다고 합니다.\(개인적으로는 해당 내용이 엄청난 효과 같습니다.\)  
네이버 해당 검색 SRE 팀은 통계를 내보니 2017년부터 2019년까지 **업데이트 대비 장애 비율이상당히 많이 감소**했다고 합니다.

### 본인의 자세 및.. 재난 엔지니어링이란 ? <a id="SRE(SiteReliabilityEngineering)-&#xBCF8;&#xC778;&#xC758;&#xC790;&#xC138;&#xBC0F;..&#xC7AC;&#xB09C;&#xC5D4;&#xC9C0;&#xB2C8;&#xC5B4;&#xB9C1;&#xC774;&#xB780;?"></a>

또한 마지막으로 이 트랙에서 강조하는 SRE에 대한 자세 및 재난 엔진이어링에 대하여 설명을 해주는데요.

```text
자세
- 이상적인 멋진 도구가 아닌 실질적인 문제를 해결에 주력해야함
- 무식한 방법이더라도 힘겹더라도 포기하지않고 개선해야함 .
- 본인이 속한 도메인에 적절한 방법론을 적용

SRE를 통해 배운점 .
시스템 문제해결 + 안정적인 시스템 구축  = 재난 엔지니어링 

```

우리 디지털 유닛도 문화를 만들고, 해당 자세를 배우며, 본업에 충실하면 언젠가는 더 나아진 서비스를 고객들에게 제공할수 있을 것 같습니다.  
2019 deview SRE 트랙 후기를 마칩니다.

감사합니다.

